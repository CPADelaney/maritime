import io
import os
from datetime import datetime
from typing import List, Dict, Any

import httpx
import openpyxl
import psycopg2
from psycopg2.extras import execute_batch, Json

COFR_XLSX_URL = (
    "https://www.uscg.mil/Portals/0/NPFC/COFR/"
    "ECOFR%20active%20vessel%20cofr.xlsx"
)

# Example DSN: "postgres://user:pass@host:5432/postgres"
PG_DSN = os.environ["DATABASE_URL"]


def fetch_xlsx_bytes() -> bytes:
    """Download the ECOFR active vessel spreadsheet."""
    with httpx.Client(
        timeout=30,
        headers={"User-Agent": "MaritimeMVP-ETL/0.1"},
        verify=False,  # you can flip this once you're happy
    ) as client:
        r = client.get(COFR_XLSX_URL, follow_redirects=True)
        r.raise_for_status()
        return r.content


def parse_rows(data: bytes) -> List[Dict[str, Any]]:
    """Parse XLSX into a list of dict records using real headers."""
    wb = openpyxl.load_workbook(io.BytesIO(data), data_only=True)
    ws = wb.active

    header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=True))
    headers = [str(h).strip() if h is not None else "" for h in header_row]

    records: List[Dict[str, Any]] = []
    for row in ws.iter_rows(min_row=2, values_only=True):
        if all(v is None for v in row):
            continue
        rec: Dict[str, Any] = {}
        for h, v in zip(headers, row):
            if not h:
                continue
            rec[h] = v
        records.append(rec)
    return records


def _to_date(x) -> datetime.date | None:
    """Handle Excel datetime, string dates, or None."""
    if x is None:
        return None
    if isinstance(x, datetime):
        return x.date()
    s = str(x).strip()
    if not s:
        return None

    # Try a couple of sane formats
    for fmt in ("%m/%d/%Y %H:%M:%S %p", "%m/%d/%Y %H:%M:%S", "%m/%d/%Y", "%Y-%m-%d"):
        try:
            return datetime.strptime(s, fmt).date()
        except ValueError:
            continue
    # Give up gracefully
    return None


def normalize_record(raw: Dict[str, Any]) -> Dict[str, Any]:
    """
    Map Excel columns â†’ DB schema.

    Expected columns:
      Vessel Name, Vin, Vessel Type Code, Vsl Vessel Type Desc,
      Gross Tonnage, Case Control Id, Case- Examiner Id, Case- Operator Name,
      Effective Date, Expiration Date, Insurance Cancel Flag
    """
    vessel_name = (raw.get("Vessel Name") or "").strip()
    vin = (raw.get("Vin") or "").strip()

    return {
        "vessel_name": vessel_name or None,
        "vin": vin or None,
        "vessel_type_code": str(raw.get("Vessel Type Code") or "").strip() or None,
        "vessel_type_desc": str(raw.get("Vsl Vessel Type Desc") or "").strip() or None,
        "gross_tonnage": raw.get("Gross Tonnage"),
        "case_control_id": str(raw.get("Case Control Id") or "").strip() or None,
        "case_examiner_id": str(raw.get("Case- Examiner Id") or "").strip() or None,
        "case_operator_name": str(raw.get("Case- Operator Name") or "").strip() or None,
        "effective_date": _to_date(raw.get("Effective Date")),
        "expiration_date": _to_date(raw.get("Expiration Date")),
        "insurance_cancel_flag": str(raw.get("Insurance Cancel Flag") or "").strip() or None,
        "raw_record": raw,
    }


def upload_to_supabase(records: List[Dict[str, Any]]):
    """Upsert normalized COFR records into Supabase."""
    conn = psycopg2.connect(PG_DSN)
    try:
        with conn, conn.cursor() as cur:
            sql = """
            INSERT INTO public.cofr_active_vessels (
                vessel_name,
                vin,
                vessel_type_code,
                vessel_type_desc,
                gross_tonnage,
                case_control_id,
                case_examiner_id,
                case_operator_name,
                effective_date,
                expiration_date,
                insurance_cancel_flag,
                raw_record,
                last_seen_at
            )
            VALUES (
                %(vessel_name)s,
                %(vin)s,
                %(vessel_type_code)s,
                %(vessel_type_desc)s,
                %(gross_tonnage)s,
                %(case_control_id)s,
                %(case_examiner_id)s,
                %(case_operator_name)s,
                %(effective_date)s,
                %(expiration_date)s,
                %(insurance_cancel_flag)s,
                %(raw_record)s,
                now()
            )
            ON CONFLICT (COALESCE(vin, ''), lower(vessel_name))
            DO UPDATE SET
                vessel_type_code     = EXCLUDED.vessel_type_code,
                vessel_type_desc     = EXCLUDED.vessel_type_desc,
                gross_tonnage        = EXCLUDED.gross_tonnage,
                case_control_id      = EXCLUDED.case_control_id,
                case_examiner_id     = EXCLUDED.case_examiner_id,
                case_operator_name   = EXCLUDED.case_operator_name,
                effective_date       = EXCLUDED.effective_date,
                expiration_date      = EXCLUDED.expiration_date,
                insurance_cancel_flag= EXCLUDED.insurance_cancel_flag,
                raw_record           = EXCLUDED.raw_record,
                last_seen_at         = now();
            """
            batch = []
            for r in records:
                r = r.copy()
                r["raw_record"] = Json(r["raw_record"])
                batch.append(r)
            execute_batch(cur, sql, batch, page_size=500)
    finally:
        conn.close()


def main():
    data = fetch_xlsx_bytes()
    raw_records = parse_rows(data)
    normalized = [normalize_record(r) for r in raw_records if r]
    upload_to_supabase(normalized)


if __name__ == "__main__":
    main()
